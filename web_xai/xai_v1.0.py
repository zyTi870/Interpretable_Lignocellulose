import streamlit as st
import os
import sys
import numpy as np
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from lime import lime_image

# ==========================================
# 0. ç¯å¢ƒè®¾ç½®ä¸è·¯å¾„
# ==========================================
sys.path.append(os.getcwd())

# å°è¯•å¯¼å…¥æ¨¡å‹
try:
    from models.resnet3d import resnet18_3d, resnet50_3d
    from models.densenet3d import densenet121_3d
    from models.vit3d import ViT3D
except ImportError:
    st.error("æ— æ³•å¯¼å…¥æ¨¡å‹æ–‡ä»¶ã€‚è¯·ç¡®ä¿ models/ æ–‡ä»¶å¤¹åœ¨å½“å‰ç›®å½•ä¸‹ã€‚")
    st.stop()

# ==========================================
# 1. é¢„å¤„ç†é€»è¾‘ (å®Œå…¨å¤åˆ» cell_fiber_dataset.py)
# ==========================================
def preprocess_volume(volume, target_depth=64):
    """
    å¯¹å•æ ·æœ¬è¿›è¡Œæ¨ç†å‰å¤„ç†ï¼š
    1. æ·±åº¦è°ƒæ•´ (Pad/Crop åˆ° 64)
    2. å½’ä¸€åŒ– (0-1)
    3. ç»´åº¦å˜æ¢ (D,H,W,C) -> (C,D,H,W)
    """
    # ç¡®ä¿æ˜¯ numpy
    if isinstance(volume, torch.Tensor):
        volume = volume.numpy()

    # --- A. æ·±åº¦å¤„ç† (å¤åˆ» _process_depth) ---
    # å‡è®¾è¾“å…¥å½¢çŠ¶æ˜¯ (D, H, W, C) æˆ– (D, H, W)
    # ä½ çš„æ•°æ®ä¼¼ä¹æ˜¯ (Depth, Height, Width, Channel) = (50, 256, 256, 2)
    current_depth = volume.shape[0]

    if current_depth > target_depth:
        # æˆªå–ä¸­é—´
        start = (current_depth - target_depth) // 2
        end = start + target_depth
        volume = volume[start:end, :, :, :]
    elif current_depth < target_depth:
        # è¡¥é›¶
        pad_total = target_depth - current_depth
        pad_before = pad_total // 2
        pad_after = pad_total - pad_before
        # np.pad æ ¼å¼: ((before_D, after_D), (H, H), (W, W), (C, C))
        # é’ˆå¯¹ (D, H, W, C) ç»“æ„
        volume = np.pad(volume,
                        ((pad_before, pad_after), (0, 0), (0, 0), (0, 0)),
                        mode='constant', constant_values=0)

    # æ­¤æ—¶ volume depth å¿…å®šæ˜¯ 64

    # --- B. å½’ä¸€åŒ– (å¤åˆ» _normalize) ---
    volume = volume.astype(np.float32)
    min_val = volume.min()
    max_val = volume.max()
    if max_val - min_val > 0:
        volume = (volume - min_val) / (max_val - min_val)
    else:
        volume = volume - min_val

    # --- C. ç»´åº¦å˜æ¢ (PyTorch æ ¼å¼) ---
    # (D, H, W, C) -> (C, D, H, W)
    # transpose(3, 0, 1, 2) æŠŠæœ€åä¸€ä¸ªç»´åº¦(C)ç§»åˆ°ç¬¬ä¸€ä¸ª
    volume_ch_first = volume.transpose(3, 0, 1, 2)

    return volume_ch_first, volume # è¿”å› (Tensoræ ¼å¼, åŸå§‹å¯è§†åŒ–æ ¼å¼)

# ==========================================
# 2. ç‹¬ç«‹æ¨¡å‹åŠ è½½å‡½æ•°
# ==========================================
@st.cache_resource
def load_model_resource(model_arch, num_classes, use_cbam, checkpoint_path):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Loading {model_arch} from {checkpoint_path}...")

    try:
        if model_arch == 'ResNet18':
            model = resnet18_3d(num_classes=num_classes, use_cbam=use_cbam)
        elif model_arch == 'ResNet50':
            model = resnet50_3d(num_classes=num_classes, use_cbam=use_cbam)
        elif model_arch == 'DenseNet121':
            model = densenet121_3d(num_classes=num_classes, use_cbam=use_cbam)
        elif model_arch == 'ViT':
            model = ViT3D(num_classes=num_classes)
        else:
            return None, "Unknown Architecture"

        checkpoint = torch.load(checkpoint_path, map_location=device)
        state_dict = checkpoint['state_dict'] if 'state_dict' in checkpoint else checkpoint

        new_state_dict = {}
        for k, v in state_dict.items():
            name = k[7:] if k.startswith('module.') else k
            new_state_dict[name] = v

        model.load_state_dict(new_state_dict, strict=False)
        model.to(device)
        model.eval()
        return model, "OK"
    except Exception as e:
        return None, str(e)

# ==========================================
# 3. XAI æ ¸å¿ƒé€»è¾‘å¼•æ“
# ==========================================
class XAIEngine:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.gradients = None
        self.activations = None
        self.spatial_attn = None
        self.hook_handles = []

    def clear_hooks(self):
        for h in self.hook_handles:
            h.remove()
        self.hook_handles = []
        self.gradients = None
        self.activations = None
        self.spatial_attn = None

    def register_gradcam_hooks(self, model, target_layer):
        self.clear_hooks()
        def forward_hook(module, input, output):
            self.activations = output.detach()
        def backward_hook(module, grad_in, grad_out):
            self.gradients = grad_out[0].detach()
        h1 = target_layer.register_forward_hook(forward_hook)
        h2 = target_layer.register_backward_hook(backward_hook)
        self.hook_handles.extend([h1, h2])

    def run_gradcam(self, model, input_tensor, target_class_idx):
        model.zero_grad()
        output = model(input_tensor)

        one_hot = torch.zeros_like(output)
        one_hot[0][target_class_idx] = 1
        output.backward(gradient=one_hot, retain_graph=True)

        if self.gradients is None or self.activations is None:
            return None

        grads = self.gradients
        acts = self.activations

        # ==========================================
        # æ ¸å¿ƒä¿®å¤: ViT ç»´åº¦é€‚é…é€»è¾‘
        # ==========================================
        # CNN è¾“å‡ºé€šå¸¸æ˜¯ 5D: (B, C, D, H, W)
        # ViT è¾“å‡ºé€šå¸¸æ˜¯ 3D: (B, N_patches+1, Embed_Dim)
        if grads.ndim == 3:
            # 1. å‰”é™¤ CLS Token (é€šå¸¸åœ¨ç´¢å¼• 0)
            # shape: (B, 2049, 384) -> (B, 2048, 384)
            grads = grads[:, 1:, :]
            acts = acts[:, 1:, :]

            # 2. ç©ºé—´é‡å¡‘ (Reshape)
            # æ ¹æ® vit3d.py çš„é»˜è®¤é…ç½®:
            # Image=(64, 256, 256), Patch=(8, 16, 16)
            # Grid Dimensions: D=64/8=8, H=256/16=16, W=256/16=16
            # Total Patches = 8 * 16 * 16 = 2048
            b, n, e = grads.shape
            d_grid, h_grid, w_grid = 8, 16, 16

            # æ ¡éªŒä¸€ä¸‹æ˜¯å¦åŒ¹é…ï¼Œé˜²æ­¢å°ºå¯¸å˜äº†æŠ¥é”™
            if n != d_grid * h_grid * w_grid:
                print(f"Warning: ViT patch count {n} does not match default grid 8x16x16. Trying automatic calculation.")
                # ç®€å•å¯å‘å¼: å‡è®¾ H=W
                # n = d * h * w. è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå¦‚æœä¸å¯¹å¯èƒ½éœ€è¦æ‰‹åŠ¨è°ƒæ•´
                pass

                # (B, N, E) -> (B, D_g, H_g, W_g, E)
            grads = grads.reshape(b, d_grid, h_grid, w_grid, e)
            acts = acts.reshape(b, d_grid, h_grid, w_grid, e)

            # 3. ç»´åº¦ç½®æ¢ (Permute) ä»¥åŒ¹é… CNN æ ¼å¼ (B, C, D, H, W)
            # å½“å‰æ˜¯ (B, D, H, W, E)ï¼Œæˆ‘ä»¬éœ€è¦æŠŠ E (Channel) ç§»åˆ°ç¬¬ 1 ä½
            grads = grads.permute(0, 4, 1, 2, 3)
            acts = acts.permute(0, 4, 1, 2, 3)

        # ==========================================
        # æ ‡å‡† Grad-CAM è®¡ç®— (ç°åœ¨å…¼å®¹ ViT äº†)
        # ==========================================
        # GAP over (D, H, W) -> dim=(2, 3, 4)
        weights = torch.mean(grads, dim=(2, 3, 4), keepdim=True)
        cam = torch.sum(weights * acts, dim=1, keepdim=True)
        cam = F.relu(cam)
        cam = cam - torch.min(cam)
        cam = cam / (torch.max(cam) + 1e-7)

        # ä¸Šé‡‡æ ·å›åŸå§‹è¾“å…¥å°ºå¯¸
        cam = F.interpolate(cam, size=input_tensor.shape[2:], mode='trilinear', align_corners=False)
        return cam.cpu().numpy()[0, 0]

    def run_lime(self, model, input_tensor_batch, num_samples=200):
        """
        input_tensor_batch: (1, C, D, H, W)
        """
        explainer = lime_image.LimeImageExplainer()

        # LIME éœ€è¦ (D, H, W, C) æ ¼å¼çš„ numpy æ•°ç»„
        # input_tensor_batch[0] æ˜¯ (C, D, H, W)
        # æ­¤æ—¶éœ€è¦è½¬å› (D, H, W, C) ç»™ LIME
        img_np = input_tensor_batch[0].cpu().numpy().transpose(1, 2, 3, 0).astype(np.double)

        def predict_fn(images):
            # images: List of (D, H, W, C) -> PyTorch (N, C, D, H, W)
            imgs_np = np.array(images).transpose(0, 4, 1, 2, 3)
            tensor = torch.from_numpy(imgs_np).float().to(self.device)

            batch_size = 4
            preds = []
            with torch.no_grad():
                for i in range(0, len(tensor), batch_size):
                    batch = tensor[i:i+batch_size]
                    out = model(batch)
                    preds.append(F.softmax(out, dim=1).cpu().numpy())
            return np.concatenate(preds, axis=0)

        # 8x16x16 åˆ†å—
        def segmentation_grid_3d(image):
            segments = np.zeros(image.shape[:3], dtype=int)
            d, h, w = image.shape[:3]
            sd, sh, sw = 8, 16, 16
            idx = 0
            for z in range(0, d, sd):
                for y in range(0, h, sh):
                    for x in range(0, w, sw):
                        segments[z:min(z+sd,d), y:min(y+sh,h), x:min(x+sw,w)] = idx
                        idx += 1
            return segments

        explanation = explainer.explain_instance(
            img_np, predict_fn, labels=[0, 1, 2, 3, 4], top_labels=1,
            hide_color=0, num_samples=num_samples, segmentation_fn=segmentation_grid_3d
        )
        temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, hide_rest=False, num_features=10)
        return mask

# ==========================================
# 4. Streamlit ç•Œé¢é€»è¾‘
# ==========================================
def main():
    st.set_page_config(page_title="3D Model XAI", layout="wide")
    st.title("ğŸ”¬ 3D æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æå¹³å°")

    engine = XAIEngine()

    with st.sidebar:
        st.header("1. æ¨¡å‹é…ç½®")
        model_arch = st.selectbox("é€‰æ‹©æ¶æ„", ["ResNet18", "ResNet50", "DenseNet121", "ViT"], index=1)
        use_cbam = st.checkbox("ä½¿ç”¨ CBAM", value=True)

        ckpt_root = "./checkpoints_cbam"
        if not os.path.exists(ckpt_root):
            st.warning(f"ç›®å½•ä¸å­˜åœ¨: {ckpt_root}")
            ckpt_files = []
        else:
            ckpt_files = []
            for root, dirs, files in os.walk(ckpt_root):
                for file in files:
                    if file.endswith(".pth"):
                        ckpt_files.append(os.path.join(root, file))

        if not ckpt_files:
            st.error("æœªæ‰¾åˆ° .pth æƒé‡æ–‡ä»¶")
            st.stop()
        ckpt_path = st.selectbox("é€‰æ‹©æƒé‡æ–‡ä»¶ (.pth)", ckpt_files)

        model, msg = load_model_resource(model_arch, 5, use_cbam, ckpt_path)
        if model is None:
            st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {msg}"); st.stop()
        else:
            st.success(f"æ¨¡å‹å·²åŠ è½½: {os.path.basename(ckpt_path)}")

        st.header("2. æ•°æ®é€‰æ‹©")
        data_root = "./TRAIN_DATA_FINAL_256"
        if not os.path.exists(data_root):
            st.warning(f"ç›®å½•ä¸å­˜åœ¨: {data_root}"); data_files = []
        else:
            data_files = []
            for root, dirs, files in os.walk(data_root):
                for file in files:
                    if file.endswith(".npz"):
                        rel_path = os.path.relpath(os.path.join(root, file), start=data_root)
                        data_files.append(rel_path)

        if not data_files:
            st.error("æœªæ‰¾åˆ° .npz æ•°æ®æ–‡ä»¶"); st.stop()
        selected_file = st.selectbox("é€‰æ‹©æ•°æ®æ ·æœ¬ (.npz)", data_files)
        full_data_path = os.path.join(data_root, selected_file)

        st.header("3. åˆ†ææ–¹æ³•")
        xai_method = st.radio("é€‰æ‹©æ–¹æ³•", ["Grad-CAM", "CBAM Attention", "LIME (Slow)"])
        run_btn = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary")

    if not os.path.exists(full_data_path):
        st.stop()

    # --- æ•°æ®åŠ è½½ä¸å…³é”®é¢„å¤„ç† ---
    try:
        npz_data = np.load(full_data_path)
        keys = list(npz_data.keys())
        key = 'data' if 'data' in keys else keys[0]
        raw_data = npz_data[key]
        # å»é™¤batchç»´åº¦ (1, D, H, W, C) -> (D, H, W, C)
        if raw_data.ndim == 5: raw_data = raw_data[0]

        # æ ¸å¿ƒä¿®å¤ç‚¹ï¼šè°ƒç”¨é¢„å¤„ç†å‡½æ•°ï¼Œå°† D=50 -> D=64ï¼Œå¹¶å°† Channel ç§»åˆ°å‰é¢
        tensor_np, viz_np = preprocess_volume(raw_data, target_depth=64)

        # tensor_np: (C, D, H, W) - è¿™é‡Œçš„ C=2, D=64
        # viz_np: (D, H, W, C) - ç”¨äºå¯è§†åŒ–ï¼ŒD=64

    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½æˆ–é¢„å¤„ç†é”™è¯¯: {e}")
        st.stop()

    col1, col2 = st.columns(2)
    with col1:
        st.write(f"**æ–‡ä»¶**: `{selected_file}`")
        st.write(f"**åŸå§‹å°ºå¯¸**: `{raw_data.shape}`")
        st.write(f"**æ¨¡å‹è¾“å…¥å°ºå¯¸**: `{tensor_np.shape}` (C, D, H, W)")

    # æ„é€  Batch (1, C, D, H, W)
    input_tensor = torch.from_numpy(tensor_np).unsqueeze(0).float().to(engine.device)

    with torch.no_grad():
        outputs = model(input_tensor)
        probs = F.softmax(outputs, dim=1)
        pred_idx = torch.argmax(probs, dim=1).item()
        conf = probs[0][pred_idx].item()
        class_names = ['E', 'L', 'LQ', 'Q', 'QLX']

    with col2:
        st.metric("æ¨¡å‹é¢„æµ‹ç»“æœ", f"{class_names[pred_idx]}", f"{conf:.2%}")

    # --- åˆ†æä¸å¯è§†åŒ– ---
    if 'heatmap' not in st.session_state:
        st.session_state['heatmap'] = None

    if run_btn:
        with st.spinner(f"æ­£åœ¨è¿è¡Œ {xai_method}..."):
            engine.clear_hooks()
            heatmap = None

            if xai_method == "Grad-CAM":
                target_layer = None
                if "ResNet" in model_arch:
                    if hasattr(model, 'layer4'):
                        last_block = model.layer4[-1]
                        if hasattr(last_block, 'conv3'): target_layer = last_block.conv3
                        elif hasattr(last_block, 'conv2'): target_layer = last_block.conv2
                    else: target_layer = list(model.modules())[-2]
                elif "DenseNet" in model_arch:
                    if hasattr(model, 'features'): target_layer = model.features.denseblock4.layers[-1].conv2
                elif "ViT" in model_arch:
                    target_layer = model.norm

                if target_layer:
                    engine.register_gradcam_hooks(model, target_layer)
                    heatmap = engine.run_gradcam(model, input_tensor, pred_idx)
                else:
                    st.error("æ— æ³•å®šä½ Grad-CAM ç›®æ ‡å±‚")

            elif xai_method == "CBAM Attention":
                found = False
                for name, module in model.named_modules():
                    if 'spatial' in name.lower() and isinstance(module, torch.nn.Sigmoid):
                        def hook(m, i, o): engine.spatial_attn = o.detach()
                        module.register_forward_hook(hook)
                        found = True
                        break
                if found:
                    _ = model(input_tensor)
                    if engine.spatial_attn is not None:
                        heatmap = F.interpolate(engine.spatial_attn, size=(64, 256, 256), mode='trilinear').cpu().numpy()[0, 0]
                else:
                    st.warning("æœªæ‰¾åˆ° CBAM æ¨¡å—")

            elif xai_method.startswith("LIME"):
                heatmap = engine.run_lime(model, input_tensor, num_samples=200)

            st.session_state['heatmap'] = heatmap

    st.divider()
    st.subheader("4. äº¤äº’å¼ 3D åˆ‡ç‰‡æŸ¥çœ‹")

    # æ·±åº¦å·²ç»æ˜¯ 64 äº†
    depth_idx = st.slider("æ·±åº¦åˆ‡ç‰‡ (Z-Axis)", 0, 63, 32)

    viz_col1, viz_col2, viz_col3 = st.columns(3)

    # viz_np æ˜¯ (D, H, W, C)
    img_slice = viz_np[depth_idx, :, :, 0] # å–ç¬¬0é€šé“ç”¨äºæ˜¾ç¤º

    # å·²ç»æ˜¯ 0-1 ä¹‹é—´äº†ï¼Œä½†ä¸ºäº†ä¿é™©æ˜¾ç¤º
    img_disp = img_slice

    fig1, ax1 = plt.subplots()
    ax1.imshow(img_disp, cmap='gray')
    ax1.set_title("Processed Input (Slice)")
    ax1.axis('off')
    viz_col1.pyplot(fig1)

    if st.session_state['heatmap'] is not None:
        heatmap_vol = st.session_state['heatmap']
        map_slice = heatmap_vol[depth_idx, :, :]

        fig2, ax2 = plt.subplots()
        ax2.imshow(map_slice, cmap='jet')
        ax2.set_title(f"{xai_method} Heatmap")
        ax2.axis('off')
        viz_col2.pyplot(fig2)

        fig3, ax3 = plt.subplots()
        ax3.imshow(img_disp, cmap='gray')
        ax3.imshow(map_slice, cmap='jet', alpha=0.5)
        ax3.set_title("Overlay")
        ax3.axis('off')
        viz_col3.pyplot(fig3)
    else:
        viz_col2.info("ç‚¹å‡» 'å¼€å§‹åˆ†æ' ç”Ÿæˆçƒ­åŠ›å›¾")

if __name__ == "__main__":
    main()