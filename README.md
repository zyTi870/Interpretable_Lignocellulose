# Interpretable 3D Deep Learning for Multi-Enzyme Lignocellulose Deconstruction

[![Web XAI](https://img.shields.io/badge/Interactive-Web_XAI-blue.svg)](https://fiber-xai.kanu.edu.kg/)
[![Python 3.10](https://img.shields.io/badge/Python-3.10-green.svg)]()
[![PyTorch 2.1.2](https://img.shields.io/badge/PyTorch-2.1.2-red.svg)]()

<p align="center">
  <img src="gitpage_pic/1.webp" alt="Graphical Abstract of Interpretable 3D Deep Learning" width="90%">
</p>

This repository contains the official implementation of the study: **"Interpretable 3D deep learning identifies and reveals the spatial microstructure of multi-enzyme lignocellulose deconstruction"**. 

## ğŸ“– Overview

Understanding the spatial mechanisms of multi-enzyme lignocellulose deconstruction has traditionally been hindered by the lack of spatially resolved and non-destructive analytical methods. This project establishes an interpretable three-dimensional (3D) deep learning framework integrated with a microfluidic platform. It is designed to decode the microstructural evolution of *Caragana korshinskii* biomass under varied enzyme treatments, including cellulase, lignin peroxidase, laccase, and their synergistic combinations.

Standardized 3D volumetric datasets were constructed using dual-channel confocal laser scanning microscopy (CLSM) and analyzed via 3D convolutional neural networks (CNNs) integrated with attention mechanisms. Explainable artificial intelligence (XAI) effectively reveals distinct spatial degradation signatures, distinguishing between surface-level fragmentation and deep internal hollowing.

## ğŸŒ Interactive XAI Web Interface

To facilitate interpretation and understand the modelâ€™s decision-making process, we developed a comprehensive web-based interface. It provides interactive visualization using interpretability techniques such as Grad-CAM and CBAM. 

**Access the live XAI tool here:** [https://fiber-xai.kanu.edu.kg/](https://fiber-xai.kanu.edu.kg/)

<p align="center">
  <img src="gitpage_pic/2.webp" alt="XAI Web Interface Preview" width="90%">
</p>
*Preview of the XAI web application demonstrating 3D heatmaps and sliced views of spatial dynamics.*

## ğŸ“‚ Repository Structure

```text
â”œâ”€â”€ environment.yml             # Conda environment configuration
â”œâ”€â”€ data_processing/            # Scripts for data handling
â”‚   â”œâ”€â”€ data_loader.py          # Standardized 3D dataset loading
â”‚   â””â”€â”€ dataextand.py           # Data augmentation (rotation and cropping)
â”œâ”€â”€ gitpage_pic/                # Images for README and documentation
â”‚   â”œâ”€â”€ 1.webp                  # Graphical Abstract
â”‚   â””â”€â”€ 2.webp                  # Web XAI Preview
â”œâ”€â”€ models/                     # 3D Deep Learning Architectures
â”‚   â”œâ”€â”€ densenet3d.py           # 3D DenseNet implementations (including DenseNet121-CBAM)
â”‚   â”œâ”€â”€ resnet3d.py             # 3D ResNet variants (ResNet18, ResNet50)
â”‚   â”œâ”€â”€ vit3d.py                # 3D Vision Transformer (ViT)
â”‚   â””â”€â”€ vit3d_light.py
â”œâ”€â”€ train/                      # Training and evaluation modules
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ train.py                # Main training loop with early stopping & LR scheduler
â”œâ”€â”€ training_checkpoints/       # Saved model weights (.pth) and training logs
â”œâ”€â”€ visualization/              # Scripts for generating scientific plots
â”‚   â”œâ”€â”€ Laser_spectroscopy/     # CLSM spectral data visualization
â”‚   â”œâ”€â”€ Model_training/         # Performance metrics, loss curves, and seaborn plots
â”‚   â””â”€â”€ t-SNE/                  # t-SNE clustering analysis for feature discrimination
â””â”€â”€ web_xai/                    # Source code for the interactive Streamlit/Gradio web application
    â”œâ”€â”€ xai_v1.0.py ... xai_v3.1.py
âš™ï¸ Installation & Setup
All experiments and model training were conducted in an environment configured with Python 3.10, PyTorch 2.1.2, and CUDA 12.8.

Clone the repository:

Bash
git clone [https://github.com/yourusername/lignocellulose-3d-xai.git](https://github.com/yourusername/lignocellulose-3d-xai.git)
cd lignocellulose-3d-xai
Create the Conda environment:
Use the provided environment.yml to install all necessary dependencies.

Bash
conda env create -f environment.yml
conda activate <your_env_name>
ğŸš€ Usage
1. Data Processing
Raw .lif confocal imaging files should be converted into 2Ã—512Ã—512Ã—64 npz format. Use the data_processing scripts to apply spatial cropping and rotation, yielding the final model inputs of 2Ã—256Ã—256Ã—64 npz.

2. Model Training
To train the optimal DenseNet121-CBAM model:

Bash
python train/train.py --model densenet121_cbam --epochs 50 --batch_size 8
Training logs, validation metrics, and the best .pth weights will be saved automatically in the training_checkpoints/ directory.

3. Visualization and Interpretability
Generate scientific plots (e.g., performance comparison, t-SNE) using the scripts in the visualization/ folder:

Bash
python visualization/t-SNE/generate_tsne.py
To run the XAI web interface locally:

Bash
python web_xai/xai_v3.1.py
ğŸ† Model Performance
Our study evaluated several modern architectures. The DenseNet121-CBAM architecture achieved the optimal balance between predictive performance and generalization. It circumvents traditional "black-box" limitations by integrating channel and spatial attention mechanisms (CBAM), revealing underlying mechanisms of multi-enzyme synergy.